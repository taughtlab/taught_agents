{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799a823e-7144-400e-af73-496a3ac87987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make sure these variables are set from Step 2.1\n",
    "catalog_name = \"dev_1899989130012056\"  # Your existing catalog\n",
    "schema_name = \"ai_agents\"\n",
    "table_name = f\"{catalog_name}.{schema_name}.compliance_docs\"\n",
    "\n",
    "# Verify the table exists\n",
    "try:\n",
    "    spark.table(table_name).show(5)\n",
    "    print(f\"Table {table_name} found successfully\")\n",
    "except:\n",
    "    print(f\"Table {table_name} not found. Please run Step 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd38ef2b-6ed8-4132-8e24-f830a955070a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Option 1: Use OpenAI embeddings (simpler and more reliable)\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the API key from Databricks secrets\n",
    "OPENAI_API_KEY = dbutils.secrets.get(scope=\"ai_agent_secrets\", key=\"openai_api_key\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"Get embedding using OpenAI API\"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "# Read documents\n",
    "docs_df = spark.table(table_name).toPandas()\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "docs_df['embedding'] = docs_df['content'].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# Save back with embeddings - need to overwrite schema to add embedding column\n",
    "spark.createDataFrame(docs_df) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(table_name)\n",
    "    \n",
    "print(\"Embeddings created successfully\")\n",
    "\n",
    "# Verify embeddings were saved\n",
    "spark.sql(f\"SELECT doc_id, title, size(embedding) as embedding_size FROM {table_name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c395c6-6d21-45df-b39b-fa30c5fef85e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_similar_docs(query, k=3):\n",
    "    \"\"\"Simple vector similarity search\"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = np.array(get_embedding(query))\n",
    "    \n",
    "    # Get all documents\n",
    "    docs = spark.table(table_name).toPandas()\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for idx, row in docs.iterrows():\n",
    "        doc_embedding = np.array(row['embedding'])\n",
    "        # Cosine similarity\n",
    "        similarity = np.dot(query_embedding, doc_embedding) / (\n",
    "            np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
    "        )\n",
    "        similarities.append((similarity, row))\n",
    "    \n",
    "    # Sort and return top k\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in similarities[:k]]\n",
    "\n",
    "# Test the search\n",
    "test_results = find_similar_docs(\"What are transaction limits?\", k=2)\n",
    "print(\"Search test results:\")\n",
    "for doc in test_results:\n",
    "    print(f\"- {doc['title']}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6769488848471961,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "step_3_setup_vector_database",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
