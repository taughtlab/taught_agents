{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebae9806-e481-4b52-9f17-999664eccdfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this in the first cell of your notebook\n",
    "# Install packages one by one to ensure each succeeds\n",
    "%pip install langchain==0.1.0\n",
    "%pip install chromadb==0.4.0\n",
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install openai==1.0.0\n",
    "%pip install torch\n",
    "%pip install transformers\n",
    "\n",
    "# Restart the Python kernel after installation\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a05fb77-39d1-489a-98a3-c10e1b72fbc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this after restart to verify all packages are installed\n",
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "required_packages = ['langchain', 'chromadb', 'sentence_transformers', 'openai', 'torch', 'transformers']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"✓ {package} version {version} is installed\")\n",
    "    except:\n",
    "        print(f\"✗ {package} is NOT installed\")\n",
    "        \n",
    "# If any packages are missing, try installing them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555371a0-38fa-42c9-81e6-2f71840a8b01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import with error handling\n",
    "try:\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    import os\n",
    "    print(\"✓ All imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Trying alternative import...\")\n",
    "    \n",
    "    # Alternative: Use sentence-transformers directly\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from langchain.vectorstores import Chroma\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    import os\n",
    "    \n",
    "    # Create a custom embedding class\n",
    "    class CustomEmbeddings:\n",
    "        def __init__(self, model_name):\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "        def embed_documents(self, texts):\n",
    "            return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
    "        \n",
    "        def embed_query(self, text):\n",
    "            return self.model.encode([text], convert_to_tensor=False)[0].tolist()\n",
    "\n",
    "# Use local directory instead of DBFS for ChromaDB\n",
    "persist_directory = \"/tmp/vector_store\"\n",
    "os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "# Initialize embeddings model for CPU\n",
    "try:\n",
    "    # Try the standard way first\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Standard initialization failed: {e}\")\n",
    "    print(\"Using custom embeddings...\")\n",
    "    embeddings = CustomEmbeddings(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Test embeddings are working\n",
    "test_embedding = embeddings.embed_query(\"test\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "\n",
    "# Configure ChromaDB with local storage\n",
    "chroma_client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=persist_directory,\n",
    "    anonymized_telemetry=False\n",
    "))\n",
    "\n",
    "# Create collection\n",
    "collection_name = \"knowledge_base\"\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings,\n",
    "    client=chroma_client,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(f\"Vector store initialized at {persist_directory}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "step_2_initialize_vector_store",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
